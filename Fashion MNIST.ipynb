{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNGG7RndUY+VKfC1mpWq/la",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kirtiwardhan01/Neural-Style-/blob/master/Fashion%20MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsFarTSnSW9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets,transforms\n",
        "\n",
        "from torch import nn\n",
        "import torch.nn.functional as f\n",
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dbk--9D6WCqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5,), (0.5,))])    #There was an error here #Solved it\n",
        "#The error is due to color vs grayscale on the dataset, the dataset is grayscale.I fixed it by changing transform to\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CASHIizJWqDj",
        "colab_type": "code",
        "outputId": "a25291a4-e91e-4fe3-e72b-4775f63bc67b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 256),\n",
        "                      nn.ReLU(),\n",
        "                      #nn.Linear(128, 64),\n",
        "                      #nn.ReLU(),\n",
        "                      nn.Linear(256, 10),\n",
        "                      nn.LogSoftmax(dim=1),\n",
        "                     nn.Dropout(p=0.2))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "epoch = 10\n",
        "train_losses, test_losses = [], []\n",
        "for e in range(epoch):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "    \n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        # Take an update step and few the new weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        test_loss = 0\n",
        "        accuracy = 0\n",
        "\n",
        "        # Turn off gradients for validation, saves memory and computations\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for images, labels in testloader:\n",
        "                images = images.view(images.shape[0], -1)\n",
        "                \n",
        "                log_ps = model(images)\n",
        "                test_loss += criterion(log_ps, labels)\n",
        "                \n",
        "                ps = torch.exp(log_ps)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "                \n",
        "        train_losses.append(running_loss/len(trainloader))\n",
        "        test_losses.append(test_loss/len(testloader))\n",
        "\n",
        "        print(\"Epoch: {}/{}.. \".format(e+1, epoch),\n",
        "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
        "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
        "        #print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
        "        model.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/10..  Training Loss: 1.608..  Test Loss: 1.164..  Test Accuracy: 0.699\n",
            "Epoch: 2/10..  Training Loss: 0.985..  Test Loss: 0.875..  Test Accuracy: 0.730\n",
            "Epoch: 3/10..  Training Loss: 0.797..  Test Loss: 0.765..  Test Accuracy: 0.745\n",
            "Epoch: 4/10..  Training Loss: 0.721..  Test Loss: 0.708..  Test Accuracy: 0.754\n",
            "Epoch: 5/10..  Training Loss: 0.671..  Test Loss: 0.670..  Test Accuracy: 0.764\n",
            "Epoch: 6/10..  Training Loss: 0.638..  Test Loss: 0.642..  Test Accuracy: 0.773\n",
            "Epoch: 7/10..  Training Loss: 0.613..  Test Loss: 0.622..  Test Accuracy: 0.781\n",
            "Epoch: 8/10..  Training Loss: 0.591..  Test Loss: 0.605..  Test Accuracy: 0.784\n",
            "Epoch: 9/10..  Training Loss: 0.577..  Test Loss: 0.591..  Test Accuracy: 0.789\n",
            "Epoch: 10/10..  Training Loss: 0.560..  Test Loss: 0.577..  Test Accuracy: 0.794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2wOxEPPeBsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okAQ_mKeiktq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_network(net,trainloader):\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters, lr=0.001)\n",
        "\n",
        "    dataiter = iter(trainloader)\n",
        "    images,labels = dataiter.next()\n",
        "\n",
        "    #creating variables for inputs and targets\n",
        "    inputs = Variable(images)\n",
        "    targets = Variable(images)\n",
        "\n",
        "    #Clearing the gradients from all variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #Forward Pass then Backward pass and then updating the weights\n",
        "    output = net.forward(inputs)\n",
        "    loss = criterion(output,targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return True\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDaSOm4ilIvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "  \"\"\"imshow for Tensor\"\"\"\n",
        "  if ax is None:\n",
        "    fig,ax = plt.subplots()\n",
        "  image = image.numpy().transpose((1,2,0))\n",
        "\n",
        "  if normalize:\n",
        "    mean = np.array([0.485,0.456,0.406])\n",
        "    std = np.array([0.229,0.224,0.225])\n",
        "    image = std*image + mean\n",
        "    image = np.clip(image,0,1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top']/set_visible(False)\n",
        "    ax.spines['left']/set_visible(False)\n",
        "    ax.spines['right']/set_visible(False)\n",
        "    ax.spines['bottom']/set_visible(False)\n",
        "    ax.tick_params(axis='both',length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "    \n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmCcbsmqn6q2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def view_recon(img, recon):\n",
        "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
        "        reconstruction also a PyTorch Tensor\n",
        "    '''\n",
        "\n",
        "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
        "    axes[0].imshow(img.numpy().squeeze())\n",
        "    axes[1].imshow(recon.data.numpy().squeeze())\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box-forced')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCHcCs3BoX4l",
        "colab_type": "code",
        "outputId": "f87c351b-3b3b-4c4b-e2e8-11ac4e3746d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "model.eval()\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "img = images[0]\n",
        "# Convert 2D image to 1D vector\n",
        "img = img.view(1, 784)\n",
        "\n",
        "# Calculate the class probabilities (softmax) for img\n",
        "with torch.no_grad():\n",
        "    output = model.forward(img)\n",
        "\n",
        "ps = torch.exp(output)\n",
        "\n",
        "# Plot the image and probabilities\n",
        "view_classify(img.view(1, 28, 28), ps, version='Fashion')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scfcsIgNpVQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}